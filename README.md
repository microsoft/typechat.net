# TypeChat.NET

TypeChat.NET is an experimental project that makes it easy to build natural language interfaces using Types.

TypeChat.NET explores and applies the ideas of [TypeChat](https://github.com/microsoft/TypeChat) to .NET and integrates them with the [Microsoft Semantic Kernel](https://github.com/microsoft/semantic-kernel). 

TypeChat.NET consists of the following assemblies:
- TypeChat
- TypeChat.Schema: Classes for exporting .NET types as Typescript schema. 
- TypeChat.Program: Classes to generate, validate and execute ***JSON programs*** 
- TypeChat.SK: Integration with Semantic Kernel. 

TypeChat.NET is in **active and rapid development** with very frequent updates and refactoring. 
- **Goal**: learn how to strong typing programming with AI, particulary generative LLMs. 
- Supported scenarios are shown in the examples. Complicated schemas with generics may not work (yet). 
- Local performance may not be optimal (yet). Fortunately, most code will spend almost all of its time calling the AI.
- When in doubt, look at the code. Comments and documentation will improve as the code settles. 


## TypeChat ##
Brings TypeChat to .NET.
- Json Translators
- Json Validators

The library is a port of the TypeChat Typescript library with .NET idiom introduced as needed. But it does not implement bindings to a specific LLM model or service. For that you use the Typechat.sk library below, or roll your own.

## TypeChat.Schema ##
The library provides exporters for .NET Types to Typescript schema. 

Includes support for dynamic export at runtime, including with ***each request*** to the AI. This is needed for scenarios where the schema must include dynamic lists, such as relevant product names or lists of players in a team.

## TypeChat.Program ##
TypeChat.Program is translates natural language requests into simple programs, represented as JSON, that compose:
- Program Translators
- Program Interpreters

## TypeChat.SK ##
TypeChat.SK makes it easy to get ***strongly typed*** .NET objects from the [Microsoft Semantic Kernel](https://github.com/microsoft/semantic-kernel).

With auto-generation of Typescript schema:

        using Microsoft.TypeChat.SemanticKernel;

        // Create typed service
        _service = KernelFactory.JsonTranslator<SemanticResponse>(Config.LoadOpenAI());
        // Get typed responses
        SentimentResponse response = await service.TranslateAsync("Its a good day!");

OR with the schema for the Type generated by hand or other means:

        using Microsoft.TypeChat.SemanticKernel;

        Schema schema = Schema.Load("./SentimentSchema.ts");
        var service = KernelFactory.JsonTranslator<SentimentResponse>(
            schema,
            "gpt-35-turbo",
            _config.OpenAI
        );
        SentimentResponse response = await service.TranslateAsync("Its a good day!");


The library provides:
- LLM bindings for TypeChat using the Semantic Kernel.

# Getting Started 
## Building
You will need Visual Studio 2022. VS Code is not tested. 
- Load **typechat.sln** from the root directory of your . 
- Restore packages
- Build

## Examples

To see TypeChat in action, we recommend exploring the [TypeChat example projects](./examples). 

### Api Key
- You will need to provide an **Open API key**
- Go to the ***examples*** folder in the solution
- Create appSettings.Development.json
- Add your Api Key

### Inputs
- Each example includes an **input.txt** with sample input. 
- Pass the input file as an argument to run the example in **batch mode**. 

# Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

# Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft 
trademarks or logos is subject to and must follow 
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.
